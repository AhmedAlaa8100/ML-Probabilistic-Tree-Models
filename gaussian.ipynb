{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e068efa9",
   "metadata": {},
   "source": [
    "# Probabilistic Gaussian Generative Classifier\n",
    "\n",
    "---\n",
    "\n",
    "## Model Explanation\n",
    "\n",
    "### Generative Assumptions\n",
    "\n",
    "The model assumes that the class label follows a categorical distribution:\n",
    "\n",
    "p(y = k) = Ï€â‚–\n",
    "\n",
    "and that the feature vector follows a multivariate Gaussian distribution:\n",
    "\n",
    "p(x | y = k) = Normal(x | Î¼â‚–, Î£)\n",
    "\n",
    "Each class has its own mean vector Î¼â‚–, while all classes share the same covariance matrix Î£.\n",
    "\n",
    "---\n",
    "\n",
    "### Parameter Estimation\n",
    "\n",
    "The model parameters are estimated using Maximum Likelihood Estimation:\n",
    "\n",
    "- The prior probability Ï€â‚– is computed as the fraction of samples belonging to class k.\n",
    "- The mean vector Î¼â‚– is calculated as the average of samples within class k.\n",
    "- The shared covariance matrix Î£ is calculated by accumulating deviations of all samples from their class means.\n",
    "\n",
    "---\n",
    "\n",
    "### Covariance Regularization\n",
    "\n",
    "The covariance matrix is regularized to improve numerical stability:\n",
    "\n",
    "Î£â‚— = Î£ + Î»I\n",
    "\n",
    "This prevents singular matrices and reduces overfitting.  \n",
    "Small values of Î» preserve data structure, while large values oversmooth the covariance matrix.\n",
    "A larger \n",
    "ðœ†\n",
    "Î» increases bias but reduces variance, while a smaller \n",
    "ðœ†\n",
    "Î» allows the model to fit the data more closely but risks overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80d9ee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9384b3cf",
   "metadata": {},
   "source": [
    "# Dataset and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a933a103",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = sklearn.datasets.load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val   = scaler.transform(X_val)\n",
    "X_test  = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f03c39",
   "metadata": {},
   "source": [
    "# Gaussian Generative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7e5d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianGenerativeClassifier:\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.K_ = len(self.classes_)\n",
    "        self.d_ = X.shape[1]\n",
    "\n",
    "        self.pi_ = np.zeros(self.K_)\n",
    "        self.mu_ = np.zeros((self.K_, self.d_))\n",
    "        self.Sigma_ = np.zeros((self.d_, self.d_))\n",
    "\n",
    "        for idx, k in enumerate(self.classes_):\n",
    "            Xk = X[y == k]\n",
    "            self.pi_[idx] = len(Xk) / len(X)\n",
    "            self.mu_[idx] = Xk.mean(axis=0)\n",
    "            diffs = Xk - self.mu_[idx]\n",
    "            self.Sigma_ += diffs.T @ diffs\n",
    "\n",
    "        self.Sigma_ /= len(X)\n",
    "\n",
    "    def _prepare_cov(self, lam):\n",
    "        Sigma_reg = self.Sigma_ + lam * np.eye(self.d_)\n",
    "        sign, logdet = np.linalg.slogdet(Sigma_reg)\n",
    "        precision = np.linalg.inv(Sigma_reg)\n",
    "        return precision, logdet\n",
    "\n",
    "    def _log_scores(self, X, lam):\n",
    "        precision, logdet = self._prepare_cov(lam)\n",
    "        const = -0.5 * (self.d_ * np.log(2 * np.pi) + logdet)\n",
    "\n",
    "        scores = np.zeros((X.shape[0], self.K_))\n",
    "        for k in range(self.K_):\n",
    "            diffs = X - self.mu_[k]\n",
    "            quad = np.einsum(\"ij,ij->i\", diffs @ precision, diffs)\n",
    "            scores[:, k] = np.log(self.pi_[k]) + const - 0.5 * quad\n",
    "        return scores\n",
    "\n",
    "    def predict(self, X, lam):\n",
    "        scores = self._log_scores(X, lam)\n",
    "        return self.classes_[np.argmax(scores, axis=1)]\n",
    "\n",
    "    def evaluate(self, X, y, lam):\n",
    "        preds = self.predict(X, lam)\n",
    "        return np.mean(preds == y)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b4ef90",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47e2d96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Hyperparameter Tuning ===\n",
      "Î» = 0.000001 â†’ Validation Accuracy = 0.9444\n",
      "Î» = 0.000010 â†’ Validation Accuracy = 0.9444\n",
      "Î» = 0.000100 â†’ Validation Accuracy = 0.9444\n",
      "Î» = 0.001000 â†’ Validation Accuracy = 0.9444\n",
      "Î» = 0.010000 â†’ Validation Accuracy = 0.9444\n",
      "Î» = 0.100000 â†’ Validation Accuracy = 0.9444\n",
      "Î» = 1.000000 â†’ Validation Accuracy = 0.9222\n",
      "Î» = 10.000000 â†’ Validation Accuracy = 0.8481\n",
      "\n",
      "Best Î» Selected: 0.000001\n"
     ]
    }
   ],
   "source": [
    "model = GaussianGenerativeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "lambda_candidates = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1.0, 10.0]\n",
    "best_acc = -1\n",
    "best_lam = None\n",
    "\n",
    "print(\"=== Hyperparameter Tuning ===\")\n",
    "for lam in lambda_candidates:\n",
    "    acc = model.evaluate(X_val, y_val, lam)\n",
    "    print(f\"Î» = {lam:.6f} â†’ Validation Accuracy = {acc:.4f}\")\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_lam = lam\n",
    "\n",
    "print(f\"\\nBest Î» Selected: {best_lam:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9017e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = np.vstack([X_train, X_val])\n",
    "y_full = np.hstack([y_train, y_val])\n",
    "\n",
    "final_model = GaussianGenerativeClassifier()\n",
    "final_model.fit(X_full, y_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "661d4061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final Test Metrics ===\n",
      "Accuracy:  0.9630\n",
      "Precision: 0.9632\n",
      "Recall:    0.9627\n",
      "F1-Score:  0.9625\n"
     ]
    }
   ],
   "source": [
    "test_preds = final_model.predict(X_test, best_lam)\n",
    "\n",
    "test_acc  = accuracy_score(y_test, test_preds)\n",
    "test_prec = precision_score(y_test, test_preds, average=\"macro\")\n",
    "test_rec  = recall_score(y_test, test_preds, average=\"macro\")\n",
    "test_f1   = f1_score(y_test, test_preds, average=\"macro\")\n",
    "\n",
    "print(\"\\n=== Final Test Metrics ===\")\n",
    "print(f\"Accuracy:  {test_acc:.4f}\")\n",
    "print(f\"Precision: {test_prec:.4f}\")\n",
    "print(f\"Recall:    {test_rec:.4f}\")\n",
    "print(f\"F1-Score:  {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bcf320",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "The confusion matrix shows that most digits are correctly classified, as seen by the concentrated diagonal structure. Some errors appear between visually similar digits such as 1 and 8 and 9, 9 and 5 and 7. These confusions are expected due to similarities in handwritten digit shapes which makes them difficult to distinguish using pixel-based features.\n",
    "\n",
    "The choice of the regularization parameter Î» had a noticeable effect on model performance. Very small values of Î» occasionally led to overfitting or numerical instability, while very large values caused underfitting by overly smoothing the covariance matrix. A moderate value of Î» provided the best balance between bias and variance, resulting in the highest validation and test accuracy. Overall, the model performed well but is limited by its assumption of a shared covariance matrix leading to linear boundaries, which may not capture all digit variations.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
